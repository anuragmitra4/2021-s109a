{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hidden-senate",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS-s109A Introduction to Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-penguin",
   "metadata": {},
   "source": [
    "## Lab 6: Case Studies - Olympic Medals and COMPAS\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Summer 2021**<br/>\n",
    "**Authors:** Kevin Rader, Shivam Raval, Chris Gumb, Pavlos Protopapas and Chris Tanner\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(12345)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-communist",
   "metadata": {},
   "source": [
    "# Lab 6 Part 1: Predicting Olympic Medal Counts in 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-vietnam",
   "metadata": {},
   "source": [
    "![](medalcount.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-thermal",
   "metadata": {},
   "source": [
    "### References: \n",
    "\n",
    "World Bank Data: https://data.worldbank.org/indicator/\n",
    "\n",
    "Olympic Medal Counts: https://en.wikipedia.org/wiki/2016_Summer_Olympics_medal_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-viking",
   "metadata": {},
   "source": [
    "We'd like to predict the total medal count for the current 2020 olympics based on past history and some demographic data (really, just population and per capita GDP).  Let's firs tread in the data and do some quick EDA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-yellow",
   "metadata": {},
   "source": [
    "### 1. Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "medals00 = pd.read_csv('data/medals2000.csv', encoding = \"ISO-8859-1\")\n",
    "medals04 = pd.read_csv('data/medals2004.csv', encoding = \"ISO-8859-1\")\n",
    "medals08 = pd.read_csv('data/medals2008.csv', encoding = \"ISO-8859-1\")\n",
    "medals12 = pd.read_csv('data/medals2012.csv', encoding = \"ISO-8859-1\")\n",
    "medals16 = pd.read_csv('data/medals2016.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "gdp = pd.read_csv('data/gdp_per_capita.csv')\n",
    "pop = pd.read_csv('data/population.csv')\n",
    "\n",
    "medals00.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-newport",
   "metadata": {},
   "source": [
    "Let's do some simple EDA teating `total` medals in 2016 as the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(18,15))\n",
    "\n",
    "ax[0][0].hist(medals16['total'])\n",
    "ax[0][1].scatter(medals12['total'],medals16['total'])\n",
    "ax[1][0].hist(np.log2(medals16['total']+1))\n",
    "ax[1][1].scatter(np.log2(medals12['total']+1),np.log2(medals16['total']+1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-standard",
   "metadata": {},
   "source": [
    "Wait what, a negative correlation!?!?!?!?  What's going on?  Let's check one thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals16.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals12.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-financing",
   "metadata": {},
   "source": [
    "That explains it!  So we need to carefully [merge](), and then explore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals = medals16.merge(medals12,on=\"code\",how=\"outer\")\n",
    "medals.columns = medals.columns.str.replace(\"_x\",\"16\").str.replace(\"_y\",\"12\")\n",
    "medals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(18,15))\n",
    "\n",
    "ax[0][0].hist(medals['total16'])\n",
    "ax[0][1].scatter(medals['total16'],medals['total12'])\n",
    "ax[1][0].hist(np.log2(medals['total16']+1))\n",
    "ax[1][1].scatter(np.log2(medals['total16']+1),np.log2(medals['total12']+1))\n",
    "ax[2][0].hist(np.sqrt(medals['total16']))\n",
    "ax[2][1].scatter(np.sqrt(medals['total16']),np.sqrt(medals['total12']))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-renewal",
   "metadata": {},
   "source": [
    "Now that looks much better.  But what are the warning signs for?!?!?  Let's check one thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-partition",
   "metadata": {},
   "source": [
    "OK there's missingness!  But this is sytematic :)\n",
    "\n",
    "Note: this happened because of the way we merged.  We used `outer` join which takes the union of the two data set and fills in `NaN`s where they are missing.  If we used `inner`, then it would have taken the intersection (but would drop the observations that do not show up in the other data set...not the ideal here.\n",
    "\n",
    "**Q1.1** What values should we impute into this data set for `total16` and `total12`?  What about for `country`? Using `pd.fillna` [docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) to accomplish the task.  Be careful: order of operations matter!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-exemption",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# your code here\n",
    "#######\n",
    "\n",
    "medals['country16'] = medals['country16'].fillna(medals['country12'])\n",
    "medals['country12'] = medals['country12'].fillna(medals['country16'])\n",
    "medals = medals.fillna(0)\n",
    "medals.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-blues",
   "metadata": {},
   "source": [
    "**Q1.2** Fit a model (`lm1`) to predict total medal count in 2016 from total medal count in 2012.  Address the following:\n",
    "\n",
    "- Print out the coefficients and $R^2$\n",
    "- Interpret the coefficients carefully\n",
    "- Investigate the assumptions\n",
    "- Investigate how well Brazil ('BRA') and England ('GBR') are predicted.  Think: why are we checking these two countries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# your code here\n",
    "#######\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm1 = LinearRegression().fit(medals[['total12']], medals['total16'])\n",
    "print(\"Intercept =\",lm1.intercept_,\", Slope(s) =\",lm1.coef_)\n",
    "print(\"R-sq =\",lm1.score(medals[['total12']], medals['total16']))\n",
    "\n",
    "yhats = lm1.predict(medals[['total12']])\n",
    "resids = medals['total16'] - yhats\n",
    "\n",
    "print(\"Brazil: yhat = \", yhats[medals.code=='BRA'][0], \", resid =\", resids[medals.code=='BRA'].iloc[0])\n",
    "print(\"England: yhat = \", yhats[medals.code=='GBR'][0], \", resid =\", resids[medals.code=='GBR'].iloc[0])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(18,6))\n",
    "\n",
    "ax[0].hist(resids)\n",
    "ax[1].scatter(yhats,resids)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-pakistan",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-devices",
   "metadata": {},
   "source": [
    "**Q1.3** Incorporate total medals from 2008 as a second predictor and fir a second model (`lm2`).  Address the following:\n",
    "\n",
    "- Print out the coefficients and $R^2$\n",
    "- Interpret the coefficients carefully and compare to `lm1`\n",
    "\n",
    "Note: you'll have to do some processing first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals_raw = medals.copy()\n",
    "medals = medals.merge(medals08,on=\"code\",how=\"outer\")\n",
    "medals.columns=medals.columns[:-5].append(medals.columns[-5:]+\"08\")\n",
    "medals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals['country08'] = medals['country08'].fillna(medals['country12'])\n",
    "medals = medals.fillna(0)\n",
    "medals.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# your code here\n",
    "#######\n",
    "\n",
    "lm2 = LinearRegression().fit(medals[['total12','total08']], medals['total16'])\n",
    "print(\"Intercept =\",lm2.intercept_,\", Slope(s) =\",lm2.coef_)\n",
    "print(\"R-sq =\",lm2.score(medals[['total12','total08']], medals['total16']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-communication",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-change",
   "metadata": {},
   "source": [
    "**Q1.4** Incorporate Population and GDP into the model (use the 2016 versions of those measurements...now call it `lm3`).  Interpret the results and compare to previous work.  Do not forget to merge first (there will be some issues, so to simplify life, let's merge using `how = 'inner'`)!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# your code here\n",
    "#######\n",
    "#medals = medals_raw.copy()\n",
    "medals_raw = medals.copy()\n",
    "\n",
    "medals = medals.merge(pop[['code','2016']],on=\"code\",how=\"inner\")\n",
    "medals['pop'] = medals['2016']\n",
    "medals = medals.merge(gdp[['code','2016']],on=\"code\",how=\"inner\")\n",
    "medals['gdp'] = medals['2016_y']\n",
    "medals.shape\n",
    "#medals_raw.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals[medals['gdp'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals = medals[-(medals['gdp'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm3 = LinearRegression().fit(medals[['total12','total08','pop','gdp']], medals['total16'])\n",
    "print(\"Intercept =\",lm3.intercept_,\", Slope(s) =\",lm3.coef_)\n",
    "print(\"R-sq =\",lm3.score(medals[['total12','total08','pop','gdp']], medals['total16']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-training",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-usage",
   "metadata": {},
   "source": [
    "**Q1.5** Take a step back and think about what we have done so far.  What would you do differently?  What other predictors would you want to include?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-domain",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-intake",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-singing",
   "metadata": {},
   "source": [
    "## Lab 6 Part 2: COMPAS Case Study\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Summer 2021**<br/>\n",
    "**Authors:** Kevin Rader, Shivam Raval, Chris Gumb, Pavlos Protopapas and Chris Tanner\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL TO GET THE RIGHT FORMATTING \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(112358)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-jacob",
   "metadata": {},
   "source": [
    "# COMPAS Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-vacation",
   "metadata": {},
   "source": [
    "Reference: https://www.uclalawreview.org/injustice-ex-machina-predictive-algorithms-in-criminal-sentencing/\n",
    "\n",
    "Further Reads: https://www.technologyreview.com/2019/10/17/75285/ai-fairer-than-judge-criminal-risk-assessment-algorithm/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-program",
   "metadata": {},
   "source": [
    "Correctional Offender Management Profiling for Alternative Sanctions (COMPAS), was designed to assess a defendant’s risk of recidivism — that is, the potential risk that the defendant will commit a crime in the future. The algorithm predicts a defendant's risk of being rearrested for a crime while awaiting trial, (e.g., the period of time between their initial arrest until their trial).\n",
    "\n",
    "COMPAS’s algorithm uses a variety of factors to generate a recidivism-risk score between 1 and 10. It does this by comparing an individual’s attributes and qualities to those of known high-risk offenders and attribues a score to the individual. At an initial court hearing after someone has been arrested for a crime, the judge needs to decide whether the defendant should be put in jail while they await trial. In jurisdictions that use COMPAS, the judge is provided with the COMPAS risk assessment as an input in this decision; COMPAS recommends that \"high risk\" defendants should be jailed pending their trial. As a result, a defendant’s sentence is determined — to at least some degree — by COMPAS’s recidivism risk assessment.\n",
    "\n",
    "In forecasting who would re-offend, the algorithm made mistakes with black and white defendants but in very different ways:\n",
    "The formula was particularly likely to falsely flag black defendants as future criminals, wrongly labeling them this way at almost twice the rate as white defendants, while the white defendants were mislabeled as low risk more often than black defendants. This is an example of bias and we shall try to investigate this effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-algeria",
   "metadata": {},
   "source": [
    "### 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "compas_df = pd.read_csv('data/compas.csv')\n",
    "compas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-welcome",
   "metadata": {},
   "source": [
    "The dataset contains many variables, some of which are raw data and other are processed:\n",
    "\n",
    "**Unprocessed data**: `age`, `c_charge_degree`,`c_charge_desc`, `race`, `sex`, `priors_count`,`juv_fel_count`,`juv_misd_count`,`juv_other_count`,`length_of_stay`\n",
    "\\\n",
    "<br>\n",
    "**Pre-processed data**: `length_of_stay_thresh`, `priors_1`, `priors_234`, `priors_5plus`, `juv_fel_1plus`,`juv_misd_1plus`,`juv_other_1plus`,`charge_any_drug`,`charge_any_violence_aggression`,`charge_any_theft`\\\n",
    "<br>\n",
    "**COMPAS Outputs**: `score_text`,`decile_score`\n",
    "\\\n",
    "<br>\n",
    "**Outcome Variable**: `two_year_recid`\n",
    "\n",
    "NOTE:\n",
    "* `score_text`,`decile_score` Should not be used in building models, because they are the outcomes of the COMPAS model.\n",
    "* `length_of_stay` (and the processed `length_of_stay_thresh`) should not be used in model, because it is an outcome of the judge's decision on pretrial risk, which may be informed by COMPAS (e.g., a defendant will not spend time in jail if they are not put in jail by the judge).\n",
    "\n",
    "We will be looking at `two_year_recid`: the prediction outcome that someone who is conviced will be rearrested in the next two years\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-donna",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 1.1:</b> Compare the number of convictions based on an individual being: 1.Male or Female 2.Misdemeanor(M) or Felony(F) 3. African-American or Caucasian? What does this tell you about the data?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-investing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-commission",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 1.2:</b> Convert the above variable columns into binary or one hot encoded columns as requiered (Hint: pd.get_dummies might be helpful, especially when there are multiple categories) </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "# Process Binary Categorical Variables\n",
    "\n",
    "compas_df['sex'] = ___\n",
    "\n",
    "compas_df['felony'] = ___\n",
    "\n",
    "\n",
    "# One Hot Encode the Race Var\n",
    "one_hot_df = pd.get_dummies(___)\n",
    "compas_race_df = pd.concat(___)\n",
    "\n",
    "# Drop the Categoricl Vars\n",
    "compas_race_df = compas_race_df.drop(___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "compas_race_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-attachment",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 1.3:</b> Create a train test split of the data, with train_size = 0.8, random_state = 209 and stratified on race </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "# Make Train Test Split\n",
    "train_df, test_df = train_test_split(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-sociology",
   "metadata": {},
   "source": [
    "### 2. EDA on the unprocessed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "unproces_cols = ['age', 'priors_count', 'juv_fel_count', 'juv_misd_count', 'juv_other_count','length_of_stay','decile_score']\n",
    "\n",
    "#Separate the variables based on race\n",
    "aa_idx_train = np.where(train_df['race_African-American']==1)[0]\n",
    "cc_idx_train = np.where(train_df['race_Caucasian']==1)[0]\n",
    "non_aa_cc_idx_train = np.where(np.all([train_df['race_Caucasian']==0, train_df['race_African-American']==0], axis=0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-career",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "heated-wallet",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 2.1:</b> Plot the above predictors in a suitable plot for the two races. You should have 7 different plots for the 7 predictors. Do you see any visible trends?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-consciousness",
   "metadata": {},
   "source": [
    "<b>Note:</b> The way you present the data is extemely important in the real world. Plots can induce biases on the obersever so one should be really careful while trying to determine the type of plot what best represents the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-lambda",
   "metadata": {},
   "source": [
    "*Your interpretation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-immunology",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 2.2:</b> The trends observed in the plot above may point to some of the biases present here. Discuss why do the trends seem different for different races? Hint: it points to deeper societal issues and human biases that creep into the data</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-header",
   "metadata": {},
   "source": [
    "*Your interpretation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-carolina",
   "metadata": {},
   "source": [
    "### 3. Fit a logistic regression model to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-biodiversity",
   "metadata": {},
   "source": [
    "Lets Build a logistic regression model to predict recidivism (`two_year_recid`) from the relevant predictors (including `race`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-account",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop variables in favor of their pre-processed equivalents; also drop decile_score which is the COMPAS output\n",
    "X_drop = ['priors_count', 'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
    "          'decile_score', 'two_year_recid', 'length_of_stay', 'length_of_stay_thresh']\n",
    "X_train, X_test = train_df.drop(columns = X_drop), test_df.drop(columns = X_drop)\n",
    "y_train, y_test = train_df['two_year_recid'], test_df['two_year_recid']\n",
    "\n",
    "# Scale data to X_train\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-pathology",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 3.1:</b> Fit a logistic regression model of your choice and print the accuracy score and the model coefficients. What do the coefficients for different races tell you about its realtion to the outcome prediction?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "# Create and fit the model\n",
    "logit_model = ____\n",
    "\n",
    "# Print Accuracy score\n",
    "print('The accuracy score for the logistic regression model on the training data:')\n",
    "display(logit_model.score(X_train_scaled, y_train))\n",
    "\n",
    "# Print Coefficients\n",
    "print('The coefficients for the logistic regression model are:')\n",
    "display(pd.DataFrame(index=X_train.columns, data={'coefficients': logit_model.coef_[0]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-still",
   "metadata": {},
   "source": [
    "*Your interpretation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-retreat",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 3.2:</b> The function below is given to you to obtain the confusion matrices for predictions for different races and obtain the relevant rates. Use it for your model and interpret the results</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to report the FPR and FNR by model\n",
    "def evaluate_model(model, X_test, y_true, aa_idx, cc_idx, threshold, make_cf = True):\n",
    "    \n",
    "    y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "    y_pred = np.array([1 if y > threshold else 0 for y in y_pred_proba])\n",
    "    model_accuracy = accuracy_score(y_pred, y_true)\n",
    "    \n",
    "    cf_afam = confusion_matrix(y_true.values[aa_idx], y_pred[aa_idx])\n",
    "    confusion_afam = dict(zip(['tn','fp','fn','tp'], cf_afam.ravel()))\n",
    "    \n",
    "    cf_cau = confusion_matrix(y_true.values[cc_idx], y_pred[cc_idx])\n",
    "    confusion_caucasian = dict(zip(['tn','fp','fn','tp'], cf_cau.ravel()))\n",
    "    \n",
    "    if make_cf == True:\n",
    "        \n",
    "        print('Confusion Matrix for African-American:')\n",
    "        display(pd.DataFrame(cf_afam, \n",
    "        index=['true:0', 'true:1'], \n",
    "        columns=['pred:0', 'pred:1'] ))\n",
    "\n",
    "        print('Confusion Matrix for Caucasian:')\n",
    "        display(pd.DataFrame(cf_cau, \n",
    "        index=['true:0', 'true:1'], \n",
    "        columns=['pred:0', 'pred:1'] ))\n",
    "        \n",
    "    \n",
    "\n",
    "    fpr_afam = confusion_afam['fp'] / (confusion_afam['fp'] + confusion_afam['tn'])\n",
    "    fnr_afam = confusion_afam['fn'] / (confusion_afam['fn'] + confusion_afam['tp'])\n",
    "\n",
    "    fpr_caucasian = confusion_caucasian['fp'] / (confusion_caucasian['fp'] + confusion_caucasian['tn'])\n",
    "    fnr_caucasian = confusion_caucasian['fn'] / (confusion_caucasian['fn'] + confusion_caucasian['tp'])\n",
    "    \n",
    "    with np.errstate(all='raise'):\n",
    "        try:\n",
    "            fpr_ratio = fpr_afam/fpr_caucasian\n",
    "        except:\n",
    "            fpr_ratio = 0\n",
    "\n",
    "        try:\n",
    "            fnr_ratio = fnr_afam/fnr_caucasian\n",
    "        except:\n",
    "            fnr_ratio = 0\n",
    "\n",
    "    return dict(zip(['model_accuracy', 'fpr_afam', 'fnr_afam', 'fpr_caucasian', 'fnr_caucasian','fpr_ratio', 'fnr_ratio'],\n",
    "                    [model_accuracy, fpr_afam, fnr_afam, fpr_caucasian, fnr_caucasian, fpr_ratio, fnr_ratio]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the indexes for the two races on the test set\n",
    "aa_idx_test = np.where(test_df['race_African-American']==1)[0]\n",
    "cc_idx_test = np.where(test_df['race_Caucasian']==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-vision",
   "metadata": {},
   "source": [
    "*Your interpretation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-founder",
   "metadata": {},
   "source": [
    "### 4. Reducing bais: buiding a Race-Agnostic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-framing",
   "metadata": {},
   "source": [
    "What if race was not included as a factor? Let's refit the logistic model but this time **without** `race` as a predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-suspect",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 4.1:</b> Drop all columns related to the races and refit the logistic regression model. Again obtain the accuracy score and the model coefficients and compare yor results with those of 3.1 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "# Drop the race columns, which are the last 5 columns in the df\n",
    "X_train_scaled_no_race = ___\n",
    "X_test_scaled_no_race = ___\n",
    "\n",
    "# Fit the model\n",
    "logit_model_no_race = ____ \n",
    "\n",
    "# Print Accuracy score\n",
    "print('The accuracy score for the logistic regression model on the training data:')\n",
    "display(logit_model_no_race.score(X_train_scaled_no_race, y_train))\n",
    "\n",
    "# Print Coefficients\n",
    "print('The coefficients for the logistic regression model excluding race are:')\n",
    "display(pd.DataFrame(index=X_train.columns[:-5], data={'coefficients': logit_model_no_race.coef_[0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_model(logit_model_no_race, X_test_scaled_no_race, y_test, aa_idx_test, cc_idx_test, 0.5)\n",
    "results_df = results_df.append(pd.DataFrame(results, index=['logit_model_no_race']))\n",
    "print('The accuracy and error rates for the model on the test set are:')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-reform",
   "metadata": {},
   "source": [
    "*Your interpretation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-auckland",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 4.2:</b> Discuss whether such a model be trusted to be unbiased even if it doesn’t explicitly use a variable such as race to predict future crime? </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-fishing",
   "metadata": {},
   "source": [
    "*Your interpretation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-scenario",
   "metadata": {},
   "source": [
    "### Closing thoughts: \n",
    "Is algorithmic modeling is appropriate in this use case given the historical biases encoded in the data and the risk of amplifying these historical inequities?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-platinum",
   "metadata": {},
   "source": [
    "# Bonus Material: Tweaking the decision threshold to make fairer models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-tokyo",
   "metadata": {},
   "source": [
    "Can we reduce bias further by chaning threshold? Lets make an ROC curve for the two subgroups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_roc(name, model, ytest, xtest, idx_test, ax=None, labe=5, proba=True, skip=0):\n",
    "    initial=False\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "        initial=True\n",
    "    if proba:#for stuff like logistic regression\n",
    "        \n",
    "        y_pred = model.predict_proba(xtest)[:,0]\n",
    "        preds_proba = model.predict_proba(xtest)[:,1]      \n",
    "       \n",
    "        auc_score = roc_auc_score(y_test.values[idx_test], preds_proba[idx_test])\n",
    "        fpr, tpr, thresholds = roc_curve(y_test.values[idx_test], preds_proba[idx_test])\n",
    "    \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    if skip:\n",
    "        l=fpr.shape[0]\n",
    "        ax.plot(fpr[0:l:skip], tpr[0:l:skip], '.-', alpha=0.3, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    else:\n",
    "        ax.plot(fpr, tpr, '.-', alpha=0.3, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    label_kwargs = {}\n",
    "    label_kwargs['bbox'] = dict(\n",
    "        boxstyle='round,pad=0.3', alpha=0.2,\n",
    "    )\n",
    "    if labe!=None:\n",
    "        for k in range(0, fpr.shape[0],labe):\n",
    "            #from https://gist.github.com/podshumok/c1d1c9394335d86255b8\n",
    "            threshold = str(np.round(thresholds[k], 2))\n",
    "            ax.annotate(threshold, (fpr[k], tpr[k]), **label_kwargs)\n",
    "    if initial:\n",
    "        ax.plot([0, 1], [0, 1], 'k--')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title('ROC')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_roc(\"Afrian-American\", logit_model_no_race, y_test, X_test_scaled_no_race, aa_idx_test, ax=None, labe=60, proba=True, skip=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_roc(\"Caucasian\", logit_model_no_race, y_test, X_test_scaled_no_race, cc_idx_test, ax=None, labe=40, proba=True, skip=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-august",
   "metadata": {},
   "source": [
    "<b>1. </b> Lets choose a new single threshold for our model that may will reduce the bias between these two racial groups (as measured by the ratios of FPR and FNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results = evaluate_model(logit_model_no_race, X_test_scaled_no_race, y_test, aa_idx_test, cc_idx_test, 0.45)\n",
    "results_df = results_df.append(pd.DataFrame(results, index=['logit_model']))\n",
    "print('The accuracy and error rates for the model on the test set are:')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-exhibit",
   "metadata": {},
   "source": [
    "It doesnt seem to improve, maybe there's a optimal threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vals = np.linspace(0,1,100)\n",
    "fpr_ratios = []\n",
    "fnr_ratios = []\n",
    "accuracies = []\n",
    "for t in t_vals:\n",
    "    result = evaluate_model(logit_model_no_race, X_test_scaled_no_race, y_test, aa_idx_test, cc_idx_test, threshold=t, make_cf = False)\n",
    "    fpr_ratios.append(result['fpr_ratio'])\n",
    "    fnr_ratios.append(result['fnr_ratio'])\n",
    "    accuracies.append(result['model_accuracy'])\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(t_vals,fpr_ratios)\n",
    "plt.title(\"False Positive Ratio\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(t_vals,fnr_ratios)\n",
    "plt.title(\"False Negative Ratio\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(t_vals,accuracies)\n",
    "plt.title(\"Model Accuracies\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-architect",
   "metadata": {},
   "source": [
    "From the above graphs, a threshold around .8 could be good since the FNR ratio is nearly 1 while the FPR ratio dips close to 1. In practice, this still means we are accepting that a higher ratio of African Americans will be wrongly classified as \"high risk\". A selection that brings FPR ratio to 1 will run into the opposite problem where we have to accept a FNR ratio that is further from 1.\n",
    "\n",
    "Selecting on model accuracy alone is not a great answer since it ignores the fact that False Negative and Positive ratios remain poor. We should make sure the model accuracy doesn't dip too close to .5 as that means we are essentially doing a coin toss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-operations",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-russian",
   "metadata": {},
   "source": [
    "<b>2. </b> Another approach to reducing bias is to use different thresholds for the different racial groups to better ensure that the groups have similar false positive and false negative rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets separate datset by race\n",
    "X_test_scaled_no_race_aa = X_test_scaled_no_race[aa_idx_test]\n",
    "X_test_scaled_no_race_cc = X_test_scaled_no_race[cc_idx_test]\n",
    "y_test_aa = np.array(y_test)[aa_idx_test]\n",
    "y_test_cc = np.array(y_test)[cc_idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting FPR, FNR, and accuracy by threshold for both datasets\n",
    "fpr_aa = []\n",
    "fnr_aa = []\n",
    "accuracy_aa = []\n",
    "fpr_cc = []\n",
    "fnr_cc = []\n",
    "accuracy_cc = []\n",
    "for threshold in t_vals:\n",
    "    # Get values for AA dataset\n",
    "    y_pred_proba = logit_model_no_race.predict_proba(X_test_scaled_no_race_aa)[:,1]\n",
    "    y_preds = np.array([1 if y > threshold else 0 for y in y_pred_proba])\n",
    "    accuracy_aa.append(accuracy_score(y_preds, y_test_aa))\n",
    "    confusion_afam = dict(zip(['tn','fp','fn','tp'], confusion_matrix(y_test_aa, y_preds).ravel()))\n",
    "    fpr_aa.append(confusion_afam['fp'] / (confusion_afam['fp'] + confusion_afam['tn']))\n",
    "    fnr_aa.append(confusion_afam['fn'] / (confusion_afam['fn'] + confusion_afam['tp']))\n",
    "\n",
    "    # Get values for CC dataset\n",
    "    y_pred_proba = logit_model_no_race.predict_proba(X_test_scaled_no_race_cc)[:,1]\n",
    "    y_preds = np.array([1 if y > threshold else 0 for y in y_pred_proba])\n",
    "    accuracy_cc.append(accuracy_score(y_preds, y_test_cc))\n",
    "    confusion_caucasian = dict(zip(['tn','fp','fn','tp'], confusion_matrix(y_test_cc, y_preds).ravel()))\n",
    "    fpr_cc.append(confusion_caucasian['fp'] / (confusion_caucasian['fp'] + confusion_caucasian['tn']))\n",
    "    fnr_cc.append(confusion_caucasian['fn'] / (confusion_caucasian['fn'] + confusion_caucasian['tp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(t_vals,fnr_cc,label='FNR')\n",
    "plt.plot(t_vals,fpr_cc,label='FPR')\n",
    "plt.plot(t_vals,accuracy_cc,label='Accuracy')\n",
    "plt.title('Caucasian dataset')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(t_vals,fnr_aa,label='FNR')\n",
    "plt.plot(t_vals,fpr_aa,label='FPR')\n",
    "plt.plot(t_vals,accuracy_aa,label='Accuracy')\n",
    "plt.title('African American dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Caucasian numbers w/threshold=.4\")\n",
    "print(\"FPR = \",fpr_cc[40])\n",
    "print(\"FNR = \",fnr_cc[40])\n",
    "print(\"Accuracy = \",accuracy_cc[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"African American numbers w/threshold=.5\")\n",
    "print(\"FPR = \",fpr_aa[50])\n",
    "print(\"FNR = \",fpr_aa[50])\n",
    "print(\"Accuracy = \",accuracy_aa[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-disclosure",
   "metadata": {},
   "source": [
    "From these graphs, a threshold around .4 for Caucasians and around .5 for African Americans seems to provide equitable treatment while maintaining good accuracy rates. Model accuracy was .66 in both which was near the peak. The False Positive and False Negative rates were also very similar for both groups, hovering around .33."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-sudan",
   "metadata": {},
   "source": [
    "#### Comparing the fairness of the above two methods:\n",
    "A model satifies group fairness if the subjects in both race groups have equal probability of being assigned to the positive class. Individual fairness is achieved if two individuals with equal characteristics aside from their race have equal probability of being assigned to the positive class.\n",
    "\n",
    "The model with fixed threshold across subgroups (<b>4.1</b>) does not quite achieve group fairness as the ratios of FPR and FNR between the two groups is not quite 1. However, it does maintain individual fairness by not changing the threshold depending on the subject's race. The model with different thresholds for each subgroups (<b>4.2</b>) achieves group fairness since the groups as a whole are equally classified. However, since the thresholds change based on the individual's race, it may not be individually fair (if we assume that the predictors capture all of the relevant information about what qualifies someone to be a recidivism risk).\n",
    "\n",
    "Changing the thresholds can *reduce* bias between the two classes, but it can also affect model accuracy. We want our model to be **accurate** but also **fair**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-shakespeare",
   "metadata": {},
   "source": [
    "## HW: Try different approaches introduced in the class to see if you can make a better performing fair model with higher accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
