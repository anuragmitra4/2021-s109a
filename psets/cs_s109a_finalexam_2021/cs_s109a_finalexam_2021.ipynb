{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://github.com/Harvard-IACS/2021-s109a/blob/master/lectures/crest.png?raw=true\"> CS-S109A Introduction to Data Science \n",
    "\n",
    "## Final Exam: COVID-19 Modeling\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Summer 2021**<br/>\n",
    "**Instructors**: Kevin Rader\n",
    "\n",
    "\n",
    "<hr style='height:2px'>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- This final exam is to be completed indivudally.  Do not consult with your peers when working on it (you can aks the teaching staff for clarification questions, including private messages on Ed).\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list.\n",
    "- Please use .head() when viewing data. Do not submit a notebook that is excessively long because output was not suppressed or otherwise limited. \n",
    "\n",
    "**Note: for all problems, it is up to you to decide how to transform the data (standardization, log transformations, etc.).  Be sure you use and interpret theses transformations approporiately.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import statsmodels as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# You are free to use any functions/methods within these packages (BS4, ELI5, and LIME are fine too)\n",
    "# if you would like to use any other, please contact hte teaching staff "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the recent spread of COVID-19 \n",
    "\n",
    "![](fig/vaccine.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are tasked with using the COVID case and vaccination data across counties presented by the CDC to analyze the recent surge in COVID infections and the association with (amonth other predictors).  You are also tasked with building prediction models to forecast how the disease spread will change based on data from the previous week (and  demographic and other measures.\n",
    "\n",
    "The exam broken into 4 problems:\n",
    "- Problem 1: Data Wrangling and Explorations\n",
    "- Problem 2: Interpretive Linear Regression Modeling\n",
    "- Problem 3: Prediction Modeling\n",
    "- Problem 4: Further Analysis\n",
    "\n",
    "You are provided with four raw data files, and a 5th cleaned file is provided to be used for all EDA and modeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables included in each of the four raw data sets are:\n",
    "\n",
    "For 'covid_cases_county.csv' (note: counties show up many times in this dataset: once for each data they report the number of cases):\n",
    "- `date`: the date of the measurement, taken weekly\n",
    "- `county`: county name\n",
    "- `state`: the state in which the county lies\n",
    "- `fips`: the unique Federal Information Processing System (FIPS) codes for the county\n",
    "- `cases`: the cumulative number of confirmed positive cases up to and including that date\n",
    "- `deaths`: the cumulative number of confirmed COVID-related deaths up to and including that date\n",
    "\n",
    "\n",
    "For 'vaccines_county.csv' (note: counties show up many times in this dataset: once for each data they report the number of cases):\n",
    "- `date`: the date of the measurement, taken weekly\n",
    "- `fips`: the unique FIPS code for the county\n",
    "- `fully`: the percent of residents that are fully vaccinated in the county on that date\n",
    "- `dose1`: the percent of residents that have received at least one vaccine dose in the county on that date.\n",
    "\n",
    "For 'masks_county.csv' (note: this is based on a survey conducted by the New York Times in summer of 2020):\n",
    "- `fips`: the unique FIPS code for the county\n",
    "- `never`: the percent of respondents that report they never wore masks in public\n",
    "- `rarely`: the percent of respondents that report they rarely wore masks in public\n",
    "- `sometimes`: the percent of respondents that report they sometimes wore masks in public\t\n",
    "- `frequently`: the percent of respondents that report they frequently wore masks in public\t\n",
    "- `always`: the percent of respondents that report they always wore masks in public\n",
    "\n",
    "For 'demographics_county.csv' (note: these are various measures taken from 2010 to 2020):\n",
    "- `fips`: the unique FIPS code for the county\n",
    "- `population`: total number of residents in the country\t\n",
    "- `hispanic`: the percentage of residents that self-identify as hispanic\n",
    "- `minority`: the percentage of residents that self-identify as a minority group (non-white)\n",
    "- `female`: the percentage of residents that self-identify as female\n",
    "- `unemployed`: the percentage of residents that are unemployed\n",
    "- `income`: the median household income, in thousnads of dollards\n",
    "- `nodegree`: the percentage of residents that report not having graduated high school\n",
    "- `bachelor`: the percentage of residents that report having a college degree\n",
    "- `inactivity`: the percentage of residents that get less than 1 hour of vigorous exercise a week\n",
    "- `obesity`: the percentage of residents that are considered obese based on BMI\n",
    "- `density`: the population density (residents per square mile)\n",
    "- `votergap20`: Biden voting percentage minus Trump voting percentage in the 2020 election\n",
    "- `votergap16`: Clinton voting percentage minus Trump voting percentage in the 2016 election\n",
    "\n",
    "\n",
    "### Data Sources\n",
    "- Vaccinations [here](https://data.cdc.gov/Vaccinations/COVID-19-Vaccinations-in-the-United-States-County/8xkx-amqh).\n",
    "- Cases [here](https://github.com/nytimes/covid-19-data).\n",
    "- Mask Usage [here](https://github.com/nytimes/covid-19-data/tree/master/mask-use).\n",
    "- Demographics [here](https://www.ers.usda.gov/data-products/county-level-data-sets/) \n",
    "- 2020 Election [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 [25pts]: Data Wrangling and Explorations </b></div>\n",
    "\n",
    "**1.1** Load the data sets as follows:\n",
    "- 'covid_cases_county.csv' as `covid_raw` \n",
    "- 'vaccines_county.csv' as `vaccines_raw`\n",
    "- 'masks_county.csv' as `masks`\n",
    "- 'demographics_county.csv' as `demo` \n",
    "\n",
    "**1.2** Create a subset of the `covid_raw` data frame that only contains the measures for 5 dates: June 27 and July 4, 11, 18 and 25.  Do the same for the `vaccines_raw`.  Call these subsets `covid` and `vaccines`, respectively, and print out their dimensions (aka, shapes).\n",
    "\n",
    "**1.3** Determine and print the number of counties that are measured for each time period in `covid` and `vaccines` (do not print out the list of counties, just the number/count).  Comment on what this implies for presence of missing data.\n",
    "\n",
    "**1.4** Process both `covid` and `vaccines` so that each county is represented by a single row in each data frame (rather than having 5 separate rows for each county: 1 for each time period in part 1.2).  Call these new generate Pandas data frames `covid_by_county` and `vaccines_by_county` separately.  Print out the dimensions of each resulting data frame, and view the header of `covid_by_county`.  Note: you should use informative names for the columns in the resulting data frames: for example, `cases_w30` for the cumulative number of cases on July 25 (it's the 30th week of the calendar year).\n",
    "\n",
    "**Hint**: Splitting based on dates and then using `pd.DataFrame.merge` (source)[https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html] could be helpful for this task using the `fips` code as the keys to join on (you should drop any counties that are not measured in all time periods...the default argument for `how` in `pd.DataFrame.merge` will behave this way).\n",
    "\n",
    "**1.5** Merge the 4 data fames (`covid_by_county`, `vaccines_by_county`, `masks`, and `demo`) based on `fips` and save the result as `covid_merged` (you should drop any counties that are not measured in all 4 data frames).  Determine and report how many counties were dropped from `demo` in this process, and view the header of `covid_merged`.\n",
    "\n",
    "**1.6** Use `covid_merged` to calculate the novel case rate (per 1000 residents) for each of the weeks for all of the counties, and save these as 4 new well-named variables in `covid_merged`.  For example, `rate_w30` can mathematically be represented as `1000*(cases_30-cases_29)/population`.  Plot the histogram of the novel case rate in week 29, `rate_w29`, and comment on what you notice.\n",
    "\n",
    "**1.7** We did the steps above (and some other minimal processing) and saved the results in `covid_clean.csv` for you.  Use this data file to answer some exploratory questions and all future analyses: \n",
    "\n",
    "1. Has the overall average case rate increased from week 28 (July 5-11) to week 29 (July 12-18)?  \n",
    "2. Treating the counties as separate and equal observations: in what states did the case rate increase the most?  In what states did the case rate decrease the most (or increse the least)?  List the top 5 for each.  Do you notice any patterns in these states?\n",
    "3. Create and interpret separate visuals to display how the country case rate in week 29 relates to each of the following variables. Interpret what you see (be specific to this domain).\n",
    "\n",
    "    a. The political views in the county (as measured by the votergap in the 2020 election).\n",
    "    \n",
    "    b. The vaccination rate in the county (for week 28) (be sure to throw away the zeros as these represent unreported values).\n",
    "    \n",
    "    c. The population density of the county.\n",
    "    \n",
    "    d. Whether 50% or more of the surveyed residents in the county report that they always wore a mask in public at the time of the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Load the data sets as follows:\n",
    "- 'covid_cases_county.csv' as `covid_raw` \n",
    "- 'vaccines_county.csv' as `vaccines_raw`\n",
    "- 'masks_county.csv' as `masks`\n",
    "- 'demographics_county.csv' as `demo` \n",
    "\n",
    "Print out each of their dimensions (aka, shapes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of covid_raw: (97394, 6)\n",
      "Shape of vaccines_raw: (96720, 4)\n",
      "Shape of masks: (3142, 6)\n",
      "Shape of demo: (3114, 14)\n"
     ]
    }
   ],
   "source": [
    "covid_raw = pd.read_csv('data/covid_cases_county.csv')\n",
    "vaccines_raw = pd.read_csv('data/vaccines_county.csv')\n",
    "masks = pd.read_csv('data/masks_county.csv')\n",
    "demo = pd.read_csv('data/demographics_county.csv')\n",
    "\n",
    "print(\"Shape of covid_raw:\", covid_raw.shape)\n",
    "print(\"Shape of vaccines_raw:\", vaccines_raw.shape)\n",
    "print(\"Shape of masks:\", masks.shape)\n",
    "print(\"Shape of demo:\", demo.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** Create a subset of the `covid_raw` data frame that only contains the measures for 5 dates: June 27 and July 4, 11, 18 and 25.  Do the same for the `vaccines_raw`.  Call these subsets `covid` and `vaccines`, respectively, and print out their dimensions (aka, shapes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of covid: (16227, 6)\n",
      "Shape of vaccines: (16120, 4)\n"
     ]
    }
   ],
   "source": [
    "covid = pd.DataFrame()\n",
    "vaccines = pd.DataFrame()\n",
    "dates = ['2021-06-27','2021-07-04','2021-07-11','2021-07-18','2021-07-25']\n",
    "\n",
    "for date in dates:\n",
    "    covid = covid.append(covid_raw[covid_raw.date == date], ignore_index=True)\n",
    "    vaccines = vaccines.append(vaccines_raw[vaccines_raw.date == date], ignore_index=True)\n",
    "    \n",
    "covid.shape\n",
    "print(\"Shape of covid:\", covid.shape)\n",
    "print(\"Shape of vaccines:\", vaccines.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3** Determine and print the number of counties that are measured for each time period in `covid` and `vaccines` (do not print out the list of counties, just the number/count).  Comment on what this implies for presence of missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of counties in `covid` on  2021-06-27    : 3219\n",
      "# of counties in `vaccines` on  2021-06-27 : 3224\n",
      "\n",
      "# of counties in `covid` on  2021-07-04    : 3219\n",
      "# of counties in `vaccines` on  2021-07-04 : 3224\n",
      "\n",
      "# of counties in `covid` on  2021-07-11    : 3219\n",
      "# of counties in `vaccines` on  2021-07-11 : 3224\n",
      "\n",
      "# of counties in `covid` on  2021-07-18    : 3219\n",
      "# of counties in `vaccines` on  2021-07-18 : 3224\n",
      "\n",
      "# of counties in `covid` on  2021-07-25    : 3219\n",
      "# of counties in `vaccines` on  2021-07-25 : 3224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for date in dates:\n",
    "    print(\"# of counties in `covid` on \", date, \"   :\",covid[covid.date==date].fips.unique().size)\n",
    "    print(\"# of counties in `vaccines` on \", date, \":\",vaccines[vaccines.date==date].fips.unique().size)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in the number of counties (3219 in `covid` and 3224 in `vaccines`) suggests that there are atleast 5 counties missing from `covid` which are present in `vaccines`. \\\n",
    "The consistent number of counties across both the datasets suggests that no counties are missing from any time period. However, we cannot be sure that no counties are missing until we actually look and compare the FIP codes over all the time periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4** Process both `covid` and `vaccines` so that each county is represented by a single row in each data frame (rather than having 5 separate rows for each county: 1 for each time period in part 1.2).  Call these new generate Pandas data frames `covid_by_county` and `vaccines_by_county` separately.  Print out the dimensions of each resulting data frame, and view the header of `covid_by_county`.  Note: you should use informative names for the columns in the resulting data frames: for example, `cases_w30` for the cumulative number of cases on July 25 (it's the 30th week of the calendar year).\n",
    "\n",
    "**Hint**: Splitting based on dates and then using `pd.DataFrame.merge` (source)[https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html] could be helpful for this task using the `fips` code as the keys to join on (you should drop any counties that are not measured in all time periods...the default argument for `how` in `pd.DataFrame.merge` will behave this way).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3245, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_x</th>\n",
       "      <th>county_x</th>\n",
       "      <th>state_x</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases_x</th>\n",
       "      <th>deaths_x</th>\n",
       "      <th>date_y</th>\n",
       "      <th>county_y</th>\n",
       "      <th>state_y</th>\n",
       "      <th>cases_y</th>\n",
       "      <th>deaths_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>7244</td>\n",
       "      <td>113.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>7262</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>21945</td>\n",
       "      <td>314.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>22043</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>2344</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2347</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2686</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2693</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>6967</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>6988</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Bullock</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1247</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Bullock</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1250</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Butler</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>2255</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Butler</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2264</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Calhoun</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>14761</td>\n",
       "      <td>330.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Calhoun</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>14778</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Chambers</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>3733</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Chambers</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>3738</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Cherokee</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1874</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Cherokee</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1874</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Chilton</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>4478</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Chilton</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4481</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Choctaw</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>620</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Choctaw</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>624</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Clarke</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>3532</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Clarke</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>3531</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Clay</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1602</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Clay</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1603</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Cleburne</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1540</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Cleburne</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1542</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>5651</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>5684</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Colbert</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>6419</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Colbert</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>6430</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Conecuh</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1138</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Conecuh</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1146</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Coosa</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>1122</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Coosa</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1123</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Covington</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>4286</td>\n",
       "      <td>123.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Covington</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4320</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Crenshaw</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>1573</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Crenshaw</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1588</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Cullman</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>9986</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Cullman</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>10014</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Dale</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>4933</td>\n",
       "      <td>117.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Dale</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4951</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>3611</td>\n",
       "      <td>158.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>3623</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>DeKalb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>9001</td>\n",
       "      <td>190.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>DeKalb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>9033</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Elmore</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>10305</td>\n",
       "      <td>214.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Elmore</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>10322</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Escambia</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>4027</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Escambia</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4038</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Etowah</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>14218</td>\n",
       "      <td>365.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Etowah</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>14249</td>\n",
       "      <td>366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>2198</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2202</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>4322</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4328</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Washburn</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>55129.0</td>\n",
       "      <td>1592</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Washburn</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1596</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>55131.0</td>\n",
       "      <td>16917</td>\n",
       "      <td>189.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>16930</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Waukesha</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>55133.0</td>\n",
       "      <td>49217</td>\n",
       "      <td>630.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Waukesha</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>49234</td>\n",
       "      <td>634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Waupaca</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>55135.0</td>\n",
       "      <td>6115</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Waupaca</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>6120</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Waushara</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>55137.0</td>\n",
       "      <td>2585</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Waushara</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2588</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Winnebago</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>55139.0</td>\n",
       "      <td>21492</td>\n",
       "      <td>225.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Winnebago</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>21514</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Wood</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>55141.0</td>\n",
       "      <td>7715</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Wood</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>7723</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56001.0</td>\n",
       "      <td>4615</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Albany</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>4652</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Big Horn</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56003.0</td>\n",
       "      <td>1200</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Big Horn</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1204</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56005.0</td>\n",
       "      <td>5176</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>5191</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Carbon</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56007.0</td>\n",
       "      <td>1627</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Carbon</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1640</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Converse</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56009.0</td>\n",
       "      <td>1035</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Converse</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1038</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Crook</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56011.0</td>\n",
       "      <td>458</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Crook</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>459</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56013.0</td>\n",
       "      <td>5299</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>5302</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Goshen</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56015.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Goshen</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1246</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Hot Springs</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56017.0</td>\n",
       "      <td>372</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Hot Springs</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>373</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56019.0</td>\n",
       "      <td>741</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>745</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Laramie</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56021.0</td>\n",
       "      <td>10305</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Laramie</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>10583</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56023.0</td>\n",
       "      <td>1422</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1432</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Natrona</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56025.0</td>\n",
       "      <td>8228</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Natrona</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>8262</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3937</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Niobrara</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56027.0</td>\n",
       "      <td>163</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Niobrara</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>163</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Park</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56029.0</td>\n",
       "      <td>2902</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Park</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2903</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3939</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Platte</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56031.0</td>\n",
       "      <td>680</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Platte</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>684</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Sheridan</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56033.0</td>\n",
       "      <td>3265</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Sheridan</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>3273</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Sublette</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56035.0</td>\n",
       "      <td>797</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Sublette</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>797</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Sweetwater</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56037.0</td>\n",
       "      <td>4729</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Sweetwater</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>4788</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Teton</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56039.0</td>\n",
       "      <td>3801</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Teton</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>3802</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Uinta</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56041.0</td>\n",
       "      <td>2315</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Uinta</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2321</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>925</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>926</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>Weston</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56045.0</td>\n",
       "      <td>656</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>Weston</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>661</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3947 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date_x     county_x    state_x     fips  cases_x  deaths_x  \\\n",
       "0     2021-06-27      Autauga    Alabama   1001.0     7244     113.0   \n",
       "1     2021-06-27      Baldwin    Alabama   1003.0    21945     314.0   \n",
       "2     2021-06-27      Barbour    Alabama   1005.0     2344      60.0   \n",
       "3     2021-06-27         Bibb    Alabama   1007.0     2686      64.0   \n",
       "4     2021-06-27       Blount    Alabama   1009.0     6967     139.0   \n",
       "5     2021-06-27      Bullock    Alabama   1011.0     1247      42.0   \n",
       "6     2021-06-27       Butler    Alabama   1013.0     2255      71.0   \n",
       "7     2021-06-27      Calhoun    Alabama   1015.0    14761     330.0   \n",
       "8     2021-06-27     Chambers    Alabama   1017.0     3733     124.0   \n",
       "9     2021-06-27     Cherokee    Alabama   1019.0     1874      45.0   \n",
       "10    2021-06-27      Chilton    Alabama   1021.0     4478     116.0   \n",
       "11    2021-06-27      Choctaw    Alabama   1023.0      620      25.0   \n",
       "12    2021-06-27       Clarke    Alabama   1025.0     3532      61.0   \n",
       "13    2021-06-27         Clay    Alabama   1027.0     1602      59.0   \n",
       "14    2021-06-27     Cleburne    Alabama   1029.0     1540      44.0   \n",
       "15    2021-06-27       Coffee    Alabama   1031.0     5651     128.0   \n",
       "16    2021-06-27      Colbert    Alabama   1033.0     6419     140.0   \n",
       "17    2021-06-27      Conecuh    Alabama   1035.0     1138      30.0   \n",
       "18    2021-06-27        Coosa    Alabama   1037.0     1122      29.0   \n",
       "19    2021-06-27    Covington    Alabama   1039.0     4286     123.0   \n",
       "20    2021-06-27     Crenshaw    Alabama   1041.0     1573      57.0   \n",
       "21    2021-06-27      Cullman    Alabama   1043.0     9986     201.0   \n",
       "22    2021-06-27         Dale    Alabama   1045.0     4933     117.0   \n",
       "23    2021-06-27       Dallas    Alabama   1047.0     3611     158.0   \n",
       "24    2021-06-27       DeKalb    Alabama   1049.0     9001     190.0   \n",
       "25    2021-06-27       Elmore    Alabama   1051.0    10305     214.0   \n",
       "26    2021-06-27     Escambia    Alabama   1053.0     4027      80.0   \n",
       "27    2021-06-27       Etowah    Alabama   1055.0    14218     365.0   \n",
       "28    2021-06-27      Fayette    Alabama   1057.0     2198      63.0   \n",
       "29    2021-06-27     Franklin    Alabama   1059.0     4322      81.0   \n",
       "...          ...          ...        ...      ...      ...       ...   \n",
       "3917  2021-06-27     Washburn  Wisconsin  55129.0     1592      24.0   \n",
       "3918  2021-06-27   Washington  Wisconsin  55131.0    16917     189.0   \n",
       "3919  2021-06-27     Waukesha  Wisconsin  55133.0    49217     630.0   \n",
       "3920  2021-06-27      Waupaca  Wisconsin  55135.0     6115     167.0   \n",
       "3921  2021-06-27     Waushara  Wisconsin  55137.0     2585      38.0   \n",
       "3922  2021-06-27    Winnebago  Wisconsin  55139.0    21492     225.0   \n",
       "3923  2021-06-27         Wood  Wisconsin  55141.0     7715     105.0   \n",
       "3924  2021-06-27       Albany    Wyoming  56001.0     4615      17.0   \n",
       "3925  2021-06-27     Big Horn    Wyoming  56003.0     1200      35.0   \n",
       "3926  2021-06-27     Campbell    Wyoming  56005.0     5176      60.0   \n",
       "3927  2021-06-27       Carbon    Wyoming  56007.0     1627      24.0   \n",
       "3928  2021-06-27     Converse    Wyoming  56009.0     1035      18.0   \n",
       "3929  2021-06-27        Crook    Wyoming  56011.0      458      12.0   \n",
       "3930  2021-06-27      Fremont    Wyoming  56013.0     5299      87.0   \n",
       "3931  2021-06-27       Goshen    Wyoming  56015.0     1240      24.0   \n",
       "3932  2021-06-27  Hot Springs    Wyoming  56017.0      372       3.0   \n",
       "3933  2021-06-27      Johnson    Wyoming  56019.0      741      10.0   \n",
       "3934  2021-06-27      Laramie    Wyoming  56021.0    10305     120.0   \n",
       "3935  2021-06-27      Lincoln    Wyoming  56023.0     1422      14.0   \n",
       "3936  2021-06-27      Natrona    Wyoming  56025.0     8228     138.0   \n",
       "3937  2021-06-27     Niobrara    Wyoming  56027.0      163       2.0   \n",
       "3938  2021-06-27         Park    Wyoming  56029.0     2902      30.0   \n",
       "3939  2021-06-27       Platte    Wyoming  56031.0      680      12.0   \n",
       "3940  2021-06-27     Sheridan    Wyoming  56033.0     3265      31.0   \n",
       "3941  2021-06-27     Sublette    Wyoming  56035.0      797       7.0   \n",
       "3942  2021-06-27   Sweetwater    Wyoming  56037.0     4729      40.0   \n",
       "3943  2021-06-27        Teton    Wyoming  56039.0     3801      11.0   \n",
       "3944  2021-06-27        Uinta    Wyoming  56041.0     2315      13.0   \n",
       "3945  2021-06-27     Washakie    Wyoming  56043.0      925      26.0   \n",
       "3946  2021-06-27       Weston    Wyoming  56045.0      656       6.0   \n",
       "\n",
       "          date_y     county_y    state_y  cases_y  deaths_y  \n",
       "0     2021-07-04      Autauga    Alabama     7262     113.0  \n",
       "1     2021-07-04      Baldwin    Alabama    22043     315.0  \n",
       "2     2021-07-04      Barbour    Alabama     2347      60.0  \n",
       "3     2021-07-04         Bibb    Alabama     2693      64.0  \n",
       "4     2021-07-04       Blount    Alabama     6988     139.0  \n",
       "5     2021-07-04      Bullock    Alabama     1250      42.0  \n",
       "6     2021-07-04       Butler    Alabama     2264      71.0  \n",
       "7     2021-07-04      Calhoun    Alabama    14778     330.0  \n",
       "8     2021-07-04     Chambers    Alabama     3738     123.0  \n",
       "9     2021-07-04     Cherokee    Alabama     1874      45.0  \n",
       "10    2021-07-04      Chilton    Alabama     4481     116.0  \n",
       "11    2021-07-04      Choctaw    Alabama      624      25.0  \n",
       "12    2021-07-04       Clarke    Alabama     3531      61.0  \n",
       "13    2021-07-04         Clay    Alabama     1603      59.0  \n",
       "14    2021-07-04     Cleburne    Alabama     1542      43.0  \n",
       "15    2021-07-04       Coffee    Alabama     5684     129.0  \n",
       "16    2021-07-04      Colbert    Alabama     6430     140.0  \n",
       "17    2021-07-04      Conecuh    Alabama     1146      30.0  \n",
       "18    2021-07-04        Coosa    Alabama     1123      29.0  \n",
       "19    2021-07-04    Covington    Alabama     4320     124.0  \n",
       "20    2021-07-04     Crenshaw    Alabama     1588      57.0  \n",
       "21    2021-07-04      Cullman    Alabama    10014     201.0  \n",
       "22    2021-07-04         Dale    Alabama     4951     117.0  \n",
       "23    2021-07-04       Dallas    Alabama     3623     159.0  \n",
       "24    2021-07-04       DeKalb    Alabama     9033     190.0  \n",
       "25    2021-07-04       Elmore    Alabama    10322     214.0  \n",
       "26    2021-07-04     Escambia    Alabama     4038      81.0  \n",
       "27    2021-07-04       Etowah    Alabama    14249     366.0  \n",
       "28    2021-07-04      Fayette    Alabama     2202      63.0  \n",
       "29    2021-07-04     Franklin    Alabama     4328      81.0  \n",
       "...          ...          ...        ...      ...       ...  \n",
       "3917  2021-07-04     Washburn  Wisconsin     1596      24.0  \n",
       "3918  2021-07-04   Washington  Wisconsin    16930     191.0  \n",
       "3919  2021-07-04     Waukesha  Wisconsin    49234     634.0  \n",
       "3920  2021-07-04      Waupaca  Wisconsin     6120     167.0  \n",
       "3921  2021-07-04     Waushara  Wisconsin     2588      38.0  \n",
       "3922  2021-07-04    Winnebago  Wisconsin    21514     225.0  \n",
       "3923  2021-07-04         Wood  Wisconsin     7723     106.0  \n",
       "3924  2021-07-04       Albany    Wyoming     4652      17.0  \n",
       "3925  2021-07-04     Big Horn    Wyoming     1204      35.0  \n",
       "3926  2021-07-04     Campbell    Wyoming     5191      60.0  \n",
       "3927  2021-07-04       Carbon    Wyoming     1640      24.0  \n",
       "3928  2021-07-04     Converse    Wyoming     1038      18.0  \n",
       "3929  2021-07-04        Crook    Wyoming      459      13.0  \n",
       "3930  2021-07-04      Fremont    Wyoming     5302      87.0  \n",
       "3931  2021-07-04       Goshen    Wyoming     1246      24.0  \n",
       "3932  2021-07-04  Hot Springs    Wyoming      373       3.0  \n",
       "3933  2021-07-04      Johnson    Wyoming      745      10.0  \n",
       "3934  2021-07-04      Laramie    Wyoming    10583     121.0  \n",
       "3935  2021-07-04      Lincoln    Wyoming     1432      14.0  \n",
       "3936  2021-07-04      Natrona    Wyoming     8262     140.0  \n",
       "3937  2021-07-04     Niobrara    Wyoming      163       2.0  \n",
       "3938  2021-07-04         Park    Wyoming     2903      32.0  \n",
       "3939  2021-07-04       Platte    Wyoming      684      13.0  \n",
       "3940  2021-07-04     Sheridan    Wyoming     3273      31.0  \n",
       "3941  2021-07-04     Sublette    Wyoming      797       7.0  \n",
       "3942  2021-07-04   Sweetwater    Wyoming     4788      40.0  \n",
       "3943  2021-07-04        Teton    Wyoming     3802      11.0  \n",
       "3944  2021-07-04        Uinta    Wyoming     2321      13.0  \n",
       "3945  2021-07-04     Washakie    Wyoming      926      26.0  \n",
       "3946  2021-07-04       Weston    Wyoming      661       6.0  \n",
       "\n",
       "[3947 rows x 11 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_w30 = covid[covid.date == '2021-06-27']\n",
    "covid_w31 = covid[covid.date == '2021-07-04']\n",
    "covid_w32 = covid[covid.date == '2021-07-11']\n",
    "covid_w33 = covid[covid.date == '2021-07-18']\n",
    "covid_w34 = covid[covid.date == '2021-07-25']\n",
    "print(covid_w30.shape)\n",
    "\n",
    "covid_w30.merge(covid[covid.date == '2021-07-04'], on='fips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5** Merge the 4 data fames (`covid_by_county`, `vaccines_by_county`, `masks`, and `demo`) based on `fips` and save the result as `covid_merged` (you should drop any counties that are not measured in all 4 data frames).  Determine and report how many counties were dropped from `demo` in this process, and view the header of `covid_merged`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6** Use `covid_merged` to calculate the novel case rate (per 1000 residents) for each of the weeks for all of the counties, and save these as 4 new well-named variables in `covid_merged`.  For example, `rate_w30` can mathematically be represented as `1000*(cases_30-cases_29)/population`.  Plot the histogram of the novel case rate in week 29, July 12-18, `rate_w29`, and comment on what you notice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.7** We did the steps above (and some other minimal processing) and saved the results in `covid_clean.csv` for you.  Use this data file to answer some exploratory questions and all future analyses: \n",
    "\n",
    "1. Has the overall average case rate increased from week 28 (July 5-11) to week 29 (July 12-18)?  \n",
    "2. Treating the counties as separate and equal observations: in what states did the case rate increase the most?  In what states did the case rate decrease the most (or increse the least)?  List the top 5 for each.  Do you notice any patterns in these states?\n",
    "3. Create and interpret separate visuals to display how the country case rate in week 29 relates to each of the following variables. Interpret what you see (be specific to this domain).\n",
    "\n",
    "    a. The political views in the county (as measured by the votergap in the 2020 election).\n",
    "    \n",
    "    b. The vaccination rate in the county (for week 28) (be sure to throw away the zeros as these represent unreported values).\n",
    "    \n",
    "    c. The population density of the county.\n",
    "    \n",
    "    d. Whether 50% or more of the surveyed residents in the county report that they always wore a mask in public at the time of the survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 [35pts]: Regression modeling \n",
    "\n",
    "**2.1** Fit a linear regression model to predict `rate_w29` (which represent the rate of new cases in the week of July 12-18) from `rate_w28` (July 5-11). Report the 95% confidence intervals for the coefficients, and carefully interpret the coefficients (including their statistical significances).  What does this model suggest about whether the rate of COVID infection increased from week 28 to week 29?\n",
    "\n",
    "\n",
    "**2.2** Fit a linear regression model to predict `rate_w29` from `rate_w28` and `votergap20` along with the interaction between the two.  Interpret the coefficient estimates carefully (no need to mention significances).\n",
    "\n",
    "\n",
    "**2.3** Create a scatterplot of `rate_w29` vs. `rate_w28`.  Add 3 separate predicted lines from your model in 2.2 to this scatterplot: the predicted line from the model in 2.2 for counties...\n",
    "    1. where Biden was favored by 50 percentage points.\n",
    "    2. where Biden and Trump were equal\n",
    "    3. where Trump was favored by 50 percentage points.\n",
    "Interpret what you see.\n",
    "\n",
    "\n",
    "**2.4** Fit a linear regression model to assess the overall association of vaccination rate (`fully_w28`) on `rate_w29`.  Carefully interpret the results (including the statistical significance).  \n",
    "\n",
    "\n",
    "**2.5** Many counties have the value zero for `fully_w28` which really represents a missing/unreported value for vaccinationr rate.  Comment on the effect of ignoring this issue can have on the intepretations and inferences in the model in 2.4.  What would be a better way of handling this issue?\n",
    "\n",
    "\n",
    "**2.6** What factors could be confounded (whether mesured here or not) with the result seen in the model from 2.3 (list up to 3)?  Fit an appropriate linear model that controls for as many of these factors as possible (for those that are measured in this data set). Interpret the coefficient estimates from this model and compare to the results from 2.4.\n",
    "\n",
    "**2.7** What major issue could arise if you fit a model to predict `rate_w29` from `rate_w28` and `rate_w27` (or from `fully_w28` and `fully_w27`) in a linear regression model?  Suggest and explain the use of two different approaches to account for this: one approach should be based on modeling and one approach should be based on feature engineering/variable transformations (not PCA). \n",
    "\n",
    "**2.8** The test set has a response variable that is `rate_w30`.  How would you use your models to predict `rate_w29` in this section in order to predict `rate_w30` instead?  Explain.  What could go wrong in this modification?\n",
    "\n",
    "**Hint**: what should be the predictors to predict `rate_w30` instead of `rate_w29`? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** Fit a linear regression model to predict `rate_w29` (which represent the rate of new cases in the week of July 12-18) from `rate_w28` (July 5-11). Report the 95% confidence intervals for the coefficients, and carefully interpret the coefficients (including their statistical significances).  What does this model suggest about whether the rate of COVID infection increased from week 28 to week 29?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** Fit a linear regression model to predict `rate_w29` from `rate_w28` and `votergap20` along with the interaction between the two.  Interpret the coefficient estimates carefully (no need to mention significances).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3** Create a scatterplot of `rate_w29` vs. `rate_w28`.  Add 3 separate predicted lines from your model in 2.2 to this scatterplot: the predicted line from the model in 2.2 for counties...\n",
    "    1. where Biden was favored by 50 percentage points.\n",
    "    2. where Biden and Trump were equal\n",
    "    3. where Trump was favored by 50 percentage points.\n",
    "Interpret what you see.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4** Fit a linear regression model to assess the overall association of vaccination rate (`fully_w28`) on `rate_w29`.  Carefully interpret the results (including the statistical significance).  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5** Many counties have the value zero for `fully_w28` which really represents a missing/unreported value for vaccinationr rate.  Comment on the effect of ignoring this issue can have on the intepretations and inferences in the model in 2.4.  What would be a better way of handling this issue?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6** What factors could be confounded (whether mesured here or not) with the result seen in the model from 2.3 (list up to 3)?  Fit an appropriate linear model that controls for as many of these factors as possible (for those that are measured in this data set). Interpret the coefficient estimates from this model and compare to the results from 2.4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.7** What major issue could arise if you fit a model to predict `rate_w29` from `rate_w28` and `rate_w27` (or from `fully_w28` and `fully_w27`) in a linear regression model?  Suggest and explain the use of two different approaches to account for this: one approach should be based on modeling and one approach should be based on feature engineering/variable transformations (not PCA). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.8** The test set has a response variable that is `rate_w30`.  How would you use your models to predict `rate_w29` in this section in order to predict `rate_w30` instead?  Explain.  What could go wrong in this modification?\n",
    "\n",
    "**Hint**: what should be the predictors to predict `rate_w30` instead of `rate_w29`? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 [30pts]: Prediction modeling \n",
    "\n",
    "**3.1** Fit a well-tuned lasso model to predict `rate_w29` from the following set of predictors (along with all 2-way interactions among the main effects and all 2nd and 3rd order polynomial terms):\n",
    "\n",
    "`['rate_w28','rate_w27','dose1_w28','hispanic','minority','female','unemployed', 'income','nodegree','bachelor','inactivity','obesity','density','votergap20']`\n",
    "\n",
    "Report and explain the best choice of $\\lambda$ (a visual can help with this), your estimate of out-of-sample $R^2$, along with the number of coefficients that shrunk exactly to zero (or numerically zero) and the number that are non-zero.\n",
    "\n",
    "**3.2** Plot the trajectory curves of the main effects `['rate_w28','rate_w27','fully_w28','votergap20']` from this model: the estimates of the $\\beta$ coefficients as a function of $\\lambda$.  Interpret what you notice.\n",
    "\n",
    "**3.3** Fit a well-tuned random forest model to predict `rate_w29` from the predictors listed in 3.1.  Report your choice of the tuning parameters and briefly justify your choices (a visual or table may be helpful for this).  Provide an estimate of out-of-sample $R^2$.  Note: do not go to crazy with the number of options for the parameters you are tuning...choose a set of values that are reasonable.\n",
    "\n",
    "**3.4** Interpret the relationship between `rate_w29` and `dose1_w28` from the random forest model in 3.3.  Is there any evidence of interactive effects in this model involving `dose1_w28`?  How do you know?  Provide a reasonable visual (or a few visuals) to help you with these tasks and interpret what you see. \n",
    "\n",
    "**3.5** Fit a well-tuned boosting model to predict `rate_w29` from the predictors listed in 3.1.  Report your best choice of the tuning parameters and briefly justify your choice (a visual or table may be helpful for this).  Provide an estimate of out-of-sample $R^2$.  Note: again, do not go to crazy with the number of options for the parameters you are tuning...choose a set of values that are reasonable.\n",
    "\n",
    "**3.6** Improve upon your favorite/best predictive model from 3.1, 3.3, or 3.5, by including other provided feature, by doing feature engineering, or by doing variable removal/selection.  Explain your choices.  Provide an estimate of out-of-sample $R^2$. \n",
    "\n",
    "**3.7** Evaluate your models from 3.1, 3.3, 3.5, and 3.6 on the test set (this will take some work...refer back to 2.8) using $R^2$.  How do these model's $R^2$ in test compare to the out-of-sample $R^2$ when tuning?  Explain whether this is surprising or not?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** Fit a well-tuned lasso model to predict `rate_w29` from the following set of predictors (along with all 2-way interactions among the main effects and all 2nd and 3rd order polynomial terms):\n",
    "\n",
    "`['rate_w28','rate_w27','dose1_w28','hispanic','minority','female','unemployed', 'income','nodegree','bachelor','inactivity','obesity','density','votergap20']`\n",
    "\n",
    "Report and explain the best choice of $\\lambda$ (a visual can help with this), your estimate of out-of-sample $R^2$, along with the number of coefficients that shrunk exactly to zero (or numerically zero) and the number that are non-zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2** Plot the trajectory curves of the main effects `['rate_w28','rate_w27','fully_w28','votergap20']` from this model: the estimates of the $\\beta$ coefficients as a function of $\\lambda$.  Interpret what you notice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3** Fit a well-tuned random forest model to predict `rate_w29` from the predictors listed in 3.1.  Report your choice of the best tuning parameters and briefly justify your choice (a visual or table may be helpful for this).  Provide an estimate of out-of-sample $R^2$.  Note: do not go to crazy with the number of options for the parameters you are tuning...choose a set of values that are reasonable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4** Interpret the relationship between `rate_w29` and `dose1_w28` from the random forest model in 3.3.  Is there any evidence of interactive effects in this model involving `dose1_w28`?  How do you know?  Provide a reasonable visual (or a few visuals) to help you with these tasks and interpret what you see. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5** Fit a well-tuned boosting model to predict `rate_w29` from the predictors listed in 3.1.  Report your best choice of the tuning parameters and briefly justify your choice (a visual or table may be helpful for this).  Provide an estimate of out-of-sample $R^2$.  Note: again, do not go to crazy with the number of options for the parameters you are tuning...choose a set of values that are reasonable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.6** Improve upon your favorite/best predictive model from 3.1, 3.3, or 3.5, by including other provided feature, by doing feature engineering, or by doing variable removal/selection.  Explain your choices.  Provide an estimate of out-of-sample $R^2$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.7** Evaluate your models from 3.1, 3.3, 3.5, and 3.6 on the test set (this will take some work...refer back to 2.8) using $R^2$.  How do these model's $R^2$ in test compare to the out-of-sample $R^2$ when tuning?  Explain whether this is surprising or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 [10pts]: Going further\n",
    "\n",
    "**4.1** Use all of the useable variables in `demo` and `masks` to create clusters of observations based on the $K$-means clustering approach.  Be sure to carefully select a reasonable choice for $K$.  Explain your choice (a visual may help with this).\n",
    "\n",
    "**4.2** Use your created clusters and incorporate them as predictor(s) into a linear regression model to assess whether the relationships you measured in the model from 2.6 depend on cluster type.  Comment on what you notice.  Determine whether out-of-sample $R^2$ has improved using this model (in comparison to the model from 2.6) based on 5-fold CV.\n",
    "\n",
    "**4.3: BONUS** Find data online to improve the prediction accuracy of your best model. Be sure to cite your source of your data and the approach you took into incorporating these new data.  Note: this is only worth up to 3 bonus points, so do not spend too much effor on this part over improving ealrier parts of the exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1** Use all of the useable variables in `demo` and `masks` to create clusters of observations based on the $K$-means clustering approach.  Be sure to carefully select a reasonable choice for $K$.  Explain your choice (a visual may help with this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2** Use your created clusters and incorporate them as predictor(s) into a linear regression model to assess whether the relationships you measured in the model from 2.6 depend on cluster type.  Comment on what you notice.  Determine whether out-of-sample $R^2$ has improved using this model (in comparison to the model from 2.6) based on 5-fold CV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3: BONUS** Find data online to improve the prediction accuracy of your best model. Be sure to cite your source of your data and the approach you took into incorporating these new data.  Note: this is only worth up to 3 bonus points, so do not spend too much effor on this part over improving ealrier parts of the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
